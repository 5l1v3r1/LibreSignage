var LexerTokenDefs = require('libresignage/markup/Lexer/LexerTokenDefs');
var LexerPostDefs = require('libresignage/markup/Lexer/LexerPostDefs');
var Lexeme = require('libresignage/markup/Lexer/Lexeme');
var LexerError = require('libresignage/markup/Lexer/LexerError')
var MarkupError = require('libresignage/markup/MarkupError')

class Lexer {
	/**
	* Post process an array of Lexemes.
	*
	* @param {Lexeme[]} lexemes An array of Lexemes.
	*
	* @return {Lexeme[]} The processed Lexeme array.
	*/
	static post(lexemes) {
		let ret = lexemes.slice();
		for (let p of LexerPostDefs) {
			ret = p.transform(ret);
		}
		return ret;
	}

	/**
	* Process a string with the lexer.
	*
	* @param {string} str The string to process.
	*/
	static process(str) {
		let ret = [];
		let ln_pos = 0;
		let ln_num = 0;
		let lexeme_index = 0;

		let lines = str.split("\n");
		for (let ln of lines) {
			while (ln_pos < ln.length) {
				let lexeme = null;

				for (let token of LexerTokenDefs.to_array()) {
					// Match token by regex.
					let match = token.match_regex(ln, ln_pos);
					if (match) {
						lexeme = new Lexeme(
							token,
							match,
							ln_num,
							ln_pos
						);

						// Match token by context.
						for (let ctx of token.get_contexts()) {
							if (ctx.match(ret.concat(lexeme), lexeme_index)) {
								ret.push(lexeme);
								ln_pos += match.length;
								lexeme_index++;
								break;
							} else {
								lexeme = null;
							}
						}
						if (lexeme) { break; }
					}
				}

				if (!lexeme) {
					throw new LexerError(
						MarkupError.code_by_abbrev('EINP'),
						'No Token matches input string.',
						ln_num,
						ln_pos
					);
				}
				lexeme = null;
			}
			ln_pos = 0;
			ln_num++;
		}
		return Lexer.post(ret);
	}
}
module.exports = Lexer;
